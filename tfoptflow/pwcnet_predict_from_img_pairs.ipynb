{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference on image pairs\n",
    "============================\n",
    "\n",
    "If you want to use a pre-trained PWC-Net model on your own set of images, you can pass a list of image pairs to a `ModelPWCNet` object using its  `predict_from_img_pairs()` method, as demonstrated here.\n",
    "\n",
    "Below, look for `TODO` references and customize this notebook based on your own needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pwcnet_predict_from_img_pairs.ipynb\n",
    "\n",
    "Run inference on a list of images pairs.\n",
    "\n",
    "Written by Phil Ferriere\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from copy import deepcopy\n",
    "from imageio import imread\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TEST_OPTIONS\n",
    "from visualize import display_img_pairs_w_flows\n",
    "from optflow import flow_to_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "def get_files(d, pattern, sort=True):\n",
    "    files = glob(osp.join(d, pattern))\n",
    "    files = [f for f in files if osp.isfile(f)]\n",
    "    if sort:\n",
    "        files.sort(key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "    return files\n",
    "\n",
    "def get_subdirs(d, nonempty=False, sort=True):\n",
    "    subdirs = [f.path for f in os.scandir(d) if f.is_dir()]\n",
    "    if nonempty:\n",
    "        subdirs = [f for f in subdirs if not is_folder_empty(f)]\n",
    "    if sort:\n",
    "        subdirs.sort(key=lambda x: x.split(\"/\")[-1])\n",
    "    return subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set device to use for inference\n",
    "# Here, we're using a GPU (use '/device:CPU:0' to run inference on the CPU)\n",
    "gpu_devices = ['/device:CPU:0']  \n",
    "controller = '/device:CPU:0'\n",
    "\n",
    "# TODO: Set the path to the trained model (make sure you've downloaded it first from http://bit.ly/tfoptflow)\n",
    "ckpt_path = './models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for inference, starting with the default options\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TEST_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = ckpt_path\n",
    "nn_opts['batch_size'] = 1\n",
    "nn_opts['gpu_devices'] = gpu_devices\n",
    "nn_opts['controller'] = controller\n",
    "\n",
    "# We're running the PWC-Net-large model in quarter-resolution mode\n",
    "# That is, with a 6 level pyramid, and upsampling of level 2 by 4 in each dimension as the final flow prediction\n",
    "nn_opts['use_dense_cx'] = True\n",
    "nn_opts['use_res_cx'] = True\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# The size of the images in this dataset are not multiples of 64, while the model generates flows padded to multiples\n",
    "# of 64. Hence, we need to crop the predicted flows to their original size\n",
    "nn_opts['adapt_info'] = (1, 436, 1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:59: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:77: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:82: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:86: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:86: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:215: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Building model...\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_pwcnet.py:1543: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_pwcnet.py:1086: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_pwcnet.py:1094: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Users/kevin/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_pwcnet.py:1221: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_pwcnet.py:1590: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "... model built.\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:119: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Loading model checkpoint ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000\n",
      "... model loaded\n",
      "\n",
      "Model Configuration:\n",
      "  verbose                True\n",
      "  ckpt_path              ./models/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000\n",
      "  x_dtype                <dtype: 'float32'>\n",
      "  x_shape                [2, None, None, 3]\n",
      "  y_dtype                <dtype: 'float32'>\n",
      "  y_shape                [None, None, 2]\n",
      "  gpu_devices            ['/device:CPU:0']\n",
      "  controller             /device:CPU:0\n",
      "  batch_size             1\n",
      "  use_tf_data            True\n",
      "  use_mixed_precision    False\n",
      "  pyr_lvls               6\n",
      "  flow_pred_lvl          2\n",
      "  search_range           4\n",
      "  use_dense_cx           True\n",
      "  use_res_cx             True\n",
      "  adapt_info             (1, 436, 1024, 2)\n",
      "  mode                   test\n",
      "WARNING:tensorflow:From /Users/kevin/repos/tfoptflow/tfoptflow/model_base.py:362: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "  trainable params       14079050\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model in inference mode and display the model configuration\n",
    "nn = ModelPWCNet(mode='test', options=nn_opts)\n",
    "nn.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting flows: 100%|###########################################| 150/150 [00:32<00:00,  4.69it/s]\n",
      "Predicting flows: 100%|###########################################| 110/110 [00:23<00:00,  4.59it/s]\n",
      "Predicting flows: 100%|#############################################| 91/91 [00:19<00:00,  4.60it/s]\n",
      "Predicting flows: 100%|#############################################| 67/67 [00:13<00:00,  4.81it/s]\n",
      "Predicting flows: 100%|###########################################| 109/109 [00:23<00:00,  4.68it/s]\n",
      "Predicting flows: 100%|#############################################| 84/84 [00:17<00:00,  4.67it/s]\n",
      "Predicting flows: 100%|###########################################| 114/114 [00:22<00:00,  4.97it/s]\n",
      "Predicting flows: 100%|#############################################| 54/54 [00:10<00:00,  4.93it/s]\n",
      "Predicting flows: 100%|###########################################| 115/115 [00:27<00:00,  4.25it/s]\n",
      "Predicting flows: 100%|###########################################| 108/108 [00:23<00:00,  4.67it/s]\n"
     ]
    }
   ],
   "source": [
    "flows = []\n",
    "frames = []\n",
    "root_dir = '/Users/kevin/repos/htl/htl/data/Penn_Action/valid/baseball_pitch/'\n",
    "for i, folder in enumerate(get_subdirs(root_dir)):\n",
    "    if i > 9:\n",
    "        break\n",
    "    files = get_files(folder, \"*.jpg\")\n",
    "    img_pairs = []\n",
    "    for pair in range(0, len(files)-1):\n",
    "        image_path1 = files[pair]\n",
    "        image_path2 = files[pair+1]\n",
    "        image1, image2 = imread(image_path1), imread(image_path2)\n",
    "        img_pairs.append((image1, image2))\n",
    "    pred_labels = nn.predict_from_img_pairs(img_pairs, batch_size=1, verbose=True)\n",
    "    # display_img_pairs_w_flows(img_pairs, pred_labels)\n",
    "    frames.append([img[0] for img in img_pairs] + [imread(files[-1])])\n",
    "    flows.append([flow_to_img(f) for f in pred_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "data = {\n",
    "    'frames': frames,\n",
    "    'embs': flows,\n",
    "}\n",
    "np.save('/Users/kevin/repos/htl/htl/tmp/flows.npy', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
